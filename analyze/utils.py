"""
ê°•í™”ëœ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ - ì ˆëŒ€ì¡°ê±´ í•„í„°ë§ ì§€ì›
JSON ì§ë ¬í™” ë° ë©”ì‹œì§€ í¬ë§·íŒ… ê°œì„ 
"""
import json
import logging
import os
import requests
import time
import numpy as np
import pandas as pd
from datetime import datetime
from logging.handlers import TimedRotatingFileHandler

def setup_logger(log_dir="logs", log_filename="buying_stocks.log", when="midnight", backup_count=7):
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_filename)

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    if logger.hasHandlers():
        logger.handlers.clear()

    # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.WARNING)
    console_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
    file_handler = TimedRotatingFileHandler(
        log_path, when=when, interval=1, backupCount=backup_count, encoding='utf-8'
    )
    file_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    file_handler.setFormatter(file_formatter)
    #file_handler.setLevel(logging.INFO)
    logger.addHandler(file_handler)

    return logger

def convert_numpy_types(obj):
    """ê°•í™”ëœ numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    # 1. numpy scalar ì²˜ë¦¬ (ê°€ì¥ ìš°ì„ )
    if hasattr(obj, 'item'):
        try:
            return obj.item()
        except (ValueError, TypeError):
            pass
    
    # 2. numpy ì •ìˆ˜í˜•ë“¤
    if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8, np.uint64, np.uint32, np.uint16, np.uint8)):
        return int(obj)
    
    # 3. numpy ì‹¤ìˆ˜í˜•ë“¤
    if isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
        return float(obj)
    
    # 4. numpy bool
    if isinstance(obj, np.bool_):
        return bool(obj)
    
    # 5. numpy ë°°ì—´
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    
    # 6. pandas íƒ€ì…ë“¤
    if isinstance(obj, pd.Series):
        return obj.tolist()
    if isinstance(obj, pd.DataFrame):
        return obj.to_dict('records')
    if hasattr(obj, 'dtype') and 'int' in str(obj.dtype):
        return int(obj) if not pd.isna(obj) else None
    if hasattr(obj, 'dtype') and 'float' in str(obj.dtype):
        return float(obj) if not pd.isna(obj) else None
    
    # 7. ì»¬ë ‰ì…˜ íƒ€ì…ë“¤ (ì¬ê·€ ì²˜ë¦¬)
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    if isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    
    # 8. ë‚ ì§œ íƒ€ì…
    if isinstance(obj, datetime):
        return obj.isoformat()
    
    # 9. ê¸°íƒ€ Python ê¸°ë³¸ íƒ€ì…ë“¤
    if isinstance(obj, (int, float, str, bool, type(None))):
        return obj
    
    # 10. ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
    try:
        if hasattr(obj, 'dtype'):
            return obj.item() if hasattr(obj, 'item') else str(obj)
        return obj
    except:
        return str(obj)

def safe_json_save(data, filename):
    """ê°•í™”ëœ ì•ˆì „í•œ JSON ì €ì¥ í•¨ìˆ˜"""
    try:
        # 1ë‹¨ê³„: numpy íƒ€ì… ë³€í™˜
        converted_data = convert_numpy_types(data)
        
        # 2ë‹¨ê³„: JSON ì§ë ¬í™” í…ŒìŠ¤íŠ¸
        test_json = json.dumps(converted_data, ensure_ascii=False, default=str)
        
        # 3ë‹¨ê³„: ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì €ì¥
        temp_filename = f"{filename}.tmp"
        with open(temp_filename, "w", encoding="utf-8") as f:
            json.dump(converted_data, f, ensure_ascii=False, indent=2, default=str)
        
        # 4ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ê²€ì¦ í›„ ì›ë³¸ìœ¼ë¡œ ì´ë™
        if os.path.exists(temp_filename) and os.path.getsize(temp_filename) > 0:
            if os.path.exists(filename):
                os.remove(filename)
            os.rename(temp_filename, filename)
            return True, None
        else:
            return False, "ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨"
        
    except Exception as e:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        temp_filename = f"{filename}.tmp"
        if os.path.exists(temp_filename):
            try:
                os.remove(temp_filename)
            except:
                pass
        return False, str(e)

def save_enhanced_backtest_candidates(candidates, logger, include_filter_info=True):
    """
    ê°•í™”ëœ ë°±í…ŒìŠ¤íŠ¸ í›„ë³´ ì €ì¥ - ì ˆëŒ€ì¡°ê±´ ì •ë³´ í¬í•¨
    
    Args:
        candidates: í›„ë³´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        logger: ë¡œê±° ê°ì²´
        include_filter_info: í•„í„°ë§ ì •ë³´ í¬í•¨ ì—¬ë¶€
    """
    try:
        if not candidates:
            logger.warning("âš ï¸ ì €ì¥í•  í›„ë³´ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ê¸°ì¡´ íŒŒì¼ë“¤ ì‚­ì œ
            files_to_delete = [
                "trading_list.json",
                "trading_list_summary.txt"
            ]
            
            deleted_files = []
            for filename in files_to_delete:
                if os.path.exists(filename):
                    try:
                        os.remove(filename)
                        deleted_files.append(filename)
                        logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ: {filename}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({filename}): {e}")
            
            if deleted_files:
                logger.info(f"âœ… ì´ {len(deleted_files)}ê°œ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            else:
                logger.info("ğŸ“ ì‚­ì œí•  ê¸°ì¡´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            return

            return
        
        # score ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_candidates = sorted(candidates, key=lambda x: x.get('score', 0), reverse=True)
        
        # ì ˆëŒ€ì¡°ê±´ í†µê³¼ ì¢…ëª©ë§Œ í•„í„°ë§ (ì´ë¯¸ í•„í„°ë§ë˜ì–´ ìˆì§€ë§Œ í™•ì‹¤íˆ)
        if include_filter_info:
            filtered_candidates = [c for c in sorted_candidates if c.get('filter_status') == 'ì ˆëŒ€ì¡°ê±´í†µê³¼']
        else:
            filtered_candidates = sorted_candidates
        
        # ìƒìœ„ 20ê°œë§Œ ì €ì¥ (ì ˆëŒ€ì¡°ê±´ í†µê³¼ ì¢…ëª©ì´ ë§ì„ ê²½ìš° ëŒ€ë¹„)
        final_candidates = filtered_candidates[:20]
        
        # ì¶”ê°€ ì •ë³´ í¬í•¨
        for candidate in final_candidates:
            candidate.update({
                'saved_at': datetime.now().isoformat(),
                'absolute_filter_applied': True,
                'ma5_below_ma20_confirmed': True,
                'foreign_selling_excluded': True
            })
        
        success, error = safe_json_save(final_candidates, "trading_list.json")
        
        if success:
            logger.info(f"âœ… trading_list.json ì €ì¥ ì™„ë£Œ: {len(final_candidates)}ê°œ ì¢…ëª© (ì ˆëŒ€ì¡°ê±´ í†µê³¼)")
            
            # ì €ì¥ëœ íŒŒì¼ ì •ë³´ ë¡œê¹…
            if os.path.exists("trading_list.json"):
                file_size = os.path.getsize("trading_list.json")
                logger.info(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {file_size} bytes")
                
                # ê°„ë‹¨ í†µê³„
                if final_candidates:
                    avg_score = sum(c.get('score', 0) for c in final_candidates) / len(final_candidates)
                    max_score = max(c.get('score', 0) for c in final_candidates)
                    logger.info(f"ğŸ“Š ì ìˆ˜ í†µê³„: í‰ê·  {avg_score:.1f}ì , ìµœê³  {max_score}ì ")
        else:
            logger.error(f"âŒ trading_list.json ì €ì¥ ì‹¤íŒ¨: {error}")
            
            # ëŒ€ì•ˆ ì €ì¥ ë°©ë²•ë“¤
            try:
                import pickle
                with open("trading_list.pkl", "wb") as f:
                    pickle.dump(final_candidates, f)
                logger.info("âœ… ëŒ€ì•ˆìœ¼ë¡œ trading_list.pklì— ì €ì¥ ì™„ë£Œ")
            except Exception as pickle_error:
                logger.error(f"âŒ pickle ì €ì¥ ì‹¤íŒ¨: {pickle_error}")
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ìš”ì•½ ì €ì¥
            try:
                with open("trading_list_summary.txt", "w", encoding="utf-8") as f:
                    f.write("# ì ˆëŒ€ì¡°ê±´ í•„í„°ë§ ì ìš© ë°±í…ŒìŠ¤íŠ¸ í›„ë³´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸\n")
                    f.write(f"# ìƒì„±ì¼ì‹œ: {datetime.now()}\n")
                    f.write(f"# ì ˆëŒ€ì¡°ê±´: 5ì¼ì„ <20ì¼ì„  + ì™¸êµ­ì¸ë§¤ìˆ˜ì¶”ì„¸\n\n")
                    
                    for i, candidate in enumerate(final_candidates, 1):
                        signals = ", ".join(candidate.get('signals', []))
                        f.write(f"{i:2d}. {candidate.get('name', 'Unknown')} ({candidate.get('code', 'N/A')})\n")
                        f.write(f"    ì ìˆ˜: {candidate.get('score', 0)}ì , ê°€ê²©: {candidate.get('price', 0):,}ì›\n")
                        f.write(f"    ì‹ í˜¸: [{signals}]\n")
                        f.write(f"    í•„í„°: {candidate.get('filter_reason', 'í†µê³¼')}\n\n")
                        
                logger.info("âœ… ëŒ€ì•ˆìœ¼ë¡œ trading_list_summary.txtì— ì €ì¥ ì™„ë£Œ")
            except Exception as txt_error:
                logger.error(f"âŒ í…ìŠ¤íŠ¸ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {txt_error}")
                
    except Exception as e:
        logger.error(f"âŒ ê°•í™”ëœ ë°±í…ŒìŠ¤íŠ¸ í›„ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
        logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {str(e)}")

def send_discord_message(message, webhook_url, max_retries=3):
    """ê°•í™”ëœ ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ì „ì†¡ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    if not webhook_url:
        print("âŒ Discord webhook URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    print(message)  # ì½˜ì†”ì—ë„ ì¶œë ¥
    
    MAX_LENGTH = 2000
    chunks = [message[i:i+MAX_LENGTH] for i in range(0, len(message), MAX_LENGTH)]
    
    success_count = 0
    for i, chunk in enumerate(chunks):
        data = {"content": chunk}
        
        for attempt in range(max_retries):
            try:
                response = requests.post(webhook_url, json=data, timeout=10)
                response.raise_for_status()
                success_count += 1
                break
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨ (ì²­í¬ {i+1}/{len(chunks)}, ì‹œë„ {attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(1 * (attempt + 1))  # ì ì§„ì  ì§€ì—°
                else:
                    print(f"âŒ ì²­í¬ {i+1} ì „ì†¡ ì™„ì „ ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ì²­í¬ {i+1}, ì‹œë„ {attempt+1}): {e}")
                break
        
        time.sleep(0.5)  # ì²­í¬ ê°„ ê°„ê²©
    
    return success_count == len(chunks)

def format_enhanced_multi_signal_message(grade, stocks):
    """ê°•í™”ëœ ë‹¤ì¤‘ì‹ í˜¸ ì¢…ëª© ë©”ì‹œì§€ í¬ë§·íŒ… (ì ˆëŒ€ì¡°ê±´ ì •ë³´ í¬í•¨)"""
    if not stocks:
        return ""
    
    grade_info = {
        "ultra_strong": {"icon": "ğŸš€", "name": "ì´ˆê°•ë ¥ ë§¤ìˆ˜ì‹ í˜¸", "desc": "5ì  ì´ìƒ", "color": "**"},
        "strong": {"icon": "ğŸ”¥", "name": "ê°•ë ¥ ë§¤ìˆ˜ì‹ í˜¸", "desc": "4ì ", "color": "**"},
        "moderate": {"icon": "â­", "name": "ë³´í†µ ë§¤ìˆ˜ì‹ í˜¸", "desc": "3ì ", "color": "**"},
        "weak": {"icon": "âš¡", "name": "ì•½í•œ ë§¤ìˆ˜ì‹ í˜¸", "desc": "2ì ", "color": ""},
        "single": {"icon": "ğŸ’¡", "name": "ë‹¨ì¼ ë§¤ìˆ˜ì‹ í˜¸", "desc": "1ì ", "color": ""}
    }
    
    info = grade_info[grade]
    header = f"{info['icon']} {info['color']}[âœ…ì ˆëŒ€ì¡°ê±´í†µê³¼ {info['name']} ({info['desc']})]**\n"
    header += "ğŸ”’ *í˜„ì¬ê°€<20ì¼ì„  + ê±°ë˜ëŸ‰â‰¥1000ì£¼ + ë³¼ë¦°ì €ë°´ë“œë‚´ + ì™¸êµ­ì¸ë§¤ìˆ˜ì¶”ì„¸*\n"
    
    stock_lines = []
    for i, stock in enumerate(sorted(stocks, key=lambda x: x.get('score', 0), reverse=True), 1):
        signals_text = ", ".join(stock.get('signals', []))
        
        # ê¸°ë³¸ ì •ë³´
        line = f"{i:2d}. **{stock.get('name', 'Unknown')} ({stock.get('code', 'N/A')})**"
        line += f" - {stock.get('score', 0)}ì \n"
        
        # ì‹ í˜¸ ì •ë³´
        line += f"     ğŸ“Š ì‹ í˜¸: [{signals_text}]\n"
        
        # ê°€ê²© ì •ë³´
        price = stock.get('price', 0)
        volume = stock.get('volume', 0)
        if price > 0:
            line += f"     ğŸ’° í˜„ì¬ê°€: {price:,}ì›, ê±°ë˜ëŸ‰: {volume:,}ì£¼\n"
        
        # ì™¸êµ­ì¸ ì •ë³´ (ê°„ì†Œí™”)
        foreign = stock.get('foreign', [])
        if foreign and len(foreign) >= 2:
            recent_foreign = sum(foreign[:2])  # ìµœê·¼ 2ì¼ í•©ê³„
            if abs(recent_foreign) > 1000:  # 1ì²œì£¼ ì´ìƒì¼ ë•Œë§Œ í‘œì‹œ
                direction = "ë§¤ìˆ˜" if recent_foreign > 0 else "ë§¤ë„"
                line += f"     ğŸŒ ì™¸êµ­ì¸ 2ì¼ê°„: {direction} {abs(recent_foreign):,}ì£¼\n"
        
        # í•„í„° í†µê³¼ ì •ë³´
        filter_reason = stock.get('filter_reason', 'ì ˆëŒ€ì¡°ê±´í†µê³¼')
        if filter_reason != 'ì ˆëŒ€ì¡°ê±´í†µê³¼':
            line += f"     âœ… ì‚¬ìœ : {filter_reason}\n"
        
        stock_lines.append(line)
    
    return header + "\n" + "\n".join(stock_lines)

def format_enhanced_signal_combination_message(combinations):
    """ê°•í™”ëœ ì‹ í˜¸ ì¡°í•© íŒ¨í„´ ë©”ì‹œì§€ í¬ë§·íŒ…"""
    if not combinations:
        return ""
    
    header = "ğŸ” **[âœ…ì ˆëŒ€ì¡°ê±´í†µê³¼ ì¸ê¸° ì‹ í˜¸ ì¡°í•© íŒ¨í„´]**\n"
    header += "ğŸ”’ *í˜„ì¬ê°€<20ì¼ì„  + ì™¸êµ­ì¸ë§¤ìˆ˜ì¶”ì„¸ ì ìš©*\n"  # ë³€ê²½
    combo_lines = []
    
    # ì¡°í•©ë³„ ì¢…ëª© ìˆ˜ë¡œ ì •ë ¬
    sorted_combos = sorted(combinations.items(), key=lambda x: len(x[1]), reverse=True)
    
    for i, (combo, stocks) in enumerate(sorted_combos[:10], 1):  # ìƒìœ„ 10ê°œ
        if len(stocks) >= 2:  # 2ê°œ ì´ìƒ ì¢…ëª©ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì¡°í•©ë§Œ
            combo_lines.append(f"{i:2d}. **{combo}** ({len(stocks)}ê°œ ì¢…ëª©)")
            
            # ì¢…ëª©ëª…ì„ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ëŠ¥í•œ ê²½ìš°)
            display_stocks = stocks[:5]  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            combo_lines.append(f"     â†’ {', '.join(display_stocks)}")
            
            if len(stocks) > 5:
                combo_lines.append(f"     â†’ *ì™¸ {len(stocks)-5}ê°œ ì¢…ëª©*")
            combo_lines.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    if combo_lines:
        # ë§ˆì§€ë§‰ ë¹ˆ ì¤„ ì œê±°
        if combo_lines[-1] == "":
            combo_lines.pop()
        return header + "\n" + "\n".join(combo_lines)
    
    return ""

def format_absolute_filter_summary(filter_passed_count, filter_failed_count, total_analyzed):
    """ì ˆëŒ€ì¡°ê±´ í•„í„°ë§ ìš”ì•½ í¬ë§·íŒ…"""
    summary_lines = []
    
    summary_lines.append("ğŸ“Š **[ì ˆëŒ€ì¡°ê±´ í•„í„°ë§ ìš”ì•½]**")
    summary_lines.append("ğŸ”’ **ì ìš©ëœ ì ˆëŒ€ì¡°ê±´:**")
    summary_lines.append("   â‘  í˜„ì¬ê°€ê°€ 20ì¼ ì´ë™í‰ê· ì„  ì•„ë˜ ìœ„ì¹˜")  # ë³€ê²½
    summary_lines.append("   â‘¡ ê±°ë˜ëŸ‰ 1000ì£¼ ì´ìƒ") 
    summary_lines.append("   â‘¢ ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ì„  ìœ„ì— ìœ„ì¹˜")
    summary_lines.append("   â‘£ ì™¸êµ­ì¸ ë§¤ìˆ˜ì¶”ì„¸")
    summary_lines.append("")
    
    summary_lines.append("ğŸ“ˆ **í•„í„°ë§ ê²°ê³¼:**")
    summary_lines.append(f"   âœ… ì ˆëŒ€ì¡°ê±´ í†µê³¼: **{filter_passed_count}ê°œ**")
    summary_lines.append(f"   ğŸš« ì ˆëŒ€ì¡°ê±´ ë¯¸í†µê³¼: {filter_failed_count}ê°œ")
    summary_lines.append(f"   ğŸ“Š ì „ì²´ ë¶„ì„ ëŒ€ìƒ: {total_analyzed}ê°œ")
    
    if filter_passed_count + filter_failed_count > 0:
        pass_rate = (filter_passed_count / (filter_passed_count + filter_failed_count)) * 100
        summary_lines.append(f"   ğŸ“ˆ ì ˆëŒ€ì¡°ê±´ í†µê³¼ìœ¨: **{pass_rate:.1f}%**")
    
    summary_lines.append("")
    summary_lines.append("ğŸ’¡ **ì˜ë¯¸:**")
    summary_lines.append("   â€¢ ëª¨ë“  í›„ë³´ëŠ” 20ì¼ì„  ì•„ë˜ ì¡°ì • êµ¬ê°„ì—ì„œ ì„ ë³„")  # ë³€ê²½
    summary_lines.append("   â€¢ ì™¸êµ­ì¸ ë§¤ìˆ˜ì¶”ì„¸ ì¢…ëª©ìœ¼ë¡œ í•œì •")
    
    return "\n".join(summary_lines)

def load_stock_codes_from_file(file_path):
    """íŒŒì¼ì—ì„œ ì¢…ëª© ì½”ë“œì™€ ì¢…ëª©ëª…ì„ ì½ì–´ì˜¤ëŠ” ê°•í™”ëœ í•¨ìˆ˜"""
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return [], {}
    
    file_extension = os.path.splitext(file_path)[1].lower()
    stock_codes = []
    stock_names = {}
    
    try:
        if file_extension == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                if data and isinstance(data[0], dict):
                    # ê°•í™”ëœ JSON êµ¬ì¡° ì²˜ë¦¬
                    for item in data:
                        if 'code' in item:
                            code = str(item['code']).zfill(6)
                            name = item.get('name', code)
                            
                            # ì ˆëŒ€ì¡°ê±´ ê´€ë ¨ ì •ë³´ í™•ì¸
                            filter_status = item.get('filter_status', '')
                            if filter_status == 'ì ˆëŒ€ì¡°ê±´í†µê³¼' or not filter_status:
                                stock_codes.append(code)
                                stock_names[code] = name
                                
                        elif 'symbol' in item:  # ë‹¤ë¥¸ í˜•ì‹ ì§€ì›
                            code = str(item['symbol']).zfill(6)
                            name = item.get('stock_name', item.get('name', code))
                            stock_codes.append(code)
                            stock_names[code] = name
                    
                    print(f"âœ… JSON ê°ì²´ ë°°ì—´ì—ì„œ {len(stock_codes)}ê°œ ì¢…ëª© ë¡œë“œ")
                else:
                    # ë‹¨ìˆœ ë°°ì—´ í˜•íƒœ
                    stock_codes = [str(code).zfill(6) for code in data]
                    stock_names = {code: code for code in stock_codes}
                    print(f"âœ… JSON ë°°ì—´ì—ì„œ {len(stock_codes)}ê°œ ì¢…ëª© ë¡œë“œ")
        
        elif file_extension == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#'):  # ì£¼ì„ ì œì™¸
                    parts = line.split()
                    if len(parts) >= 1:
                        code = parts[0].zfill(6)
                        name = parts[1] if len(parts) > 1 else code
                        stock_codes.append(code)
                        stock_names[code] = name
            
            print(f"âœ… TXT íŒŒì¼ì—ì„œ {len(stock_codes)}ê°œ ì¢…ëª© ë¡œë“œ")
        
        # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ì„± ê²€ì‚¬
        unique_codes = []
        unique_names = {}
        for code in stock_codes:
            if code and len(code) == 6 and code.isdigit():
                if code not in unique_codes:
                    unique_codes.append(code)
                    unique_names[code] = stock_names.get(code, code)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì¢…ëª©ì½”ë“œ ì œì™¸: {code}")
        
        print(f"ğŸ“Š ìµœì¢… {len(unique_codes)}ê°œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ")
        return unique_codes, unique_names
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_path}): {e}")
        return [], {}

class EnhancedProgressTracker:
    """ê°•í™”ëœ ì§„í–‰ìƒí™© ì¶”ì  í´ë˜ìŠ¤ (ì ˆëŒ€ì¡°ê±´ í†µê³„ í¬í•¨)"""
    
    def __init__(self, total_count):
        self.total_count = total_count
        self.analyzed_count = 0
        self.error_count = 0
        self.filter_passed_count = 0
        self.filter_failed_count = 0
        self.start_time = datetime.now()
        self.last_report_time = self.start_time
    
    def update(self, success=True, filter_passed=False):
        """ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì ˆëŒ€ì¡°ê±´ í†µê³¼ ì—¬ë¶€ í¬í•¨)"""
        if success:
            self.analyzed_count += 1
            if filter_passed:
                self.filter_passed_count += 1
            else:
                self.filter_failed_count += 1
        else:
            self.error_count += 1
        
        # 50ê°œë§ˆë‹¤ ë˜ëŠ” 5ë¶„ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
        total_processed = self.analyzed_count + self.error_count
        current_time = datetime.now()
        time_since_last_report = (current_time - self.last_report_time).total_seconds()
        
        if total_processed % 50 == 0 or time_since_last_report >= 300:  # 5ë¶„
            elapsed = current_time - self.start_time
            rate = total_processed / elapsed.total_seconds() * 60  # ë¶„ë‹¹ ì²˜ë¦¬ìœ¨
            
            print(f"ğŸ“Š ì§„í–‰: {total_processed}/{self.total_count} "
                  f"(ì„±ê³µ: {self.analyzed_count}, ì˜¤ë¥˜: {self.error_count}) "
                  f"âœ…í†µê³¼: {self.filter_passed_count}, ğŸš«ë¯¸í†µê³¼: {self.filter_failed_count} "
                  f"ì²˜ë¦¬ìœ¨: {rate:.1f}ê°œ/ë¶„")
            
            self.last_report_time = current_time
    
    def get_summary(self):
        """ìµœì¢… ìš”ì•½ ë°˜í™˜ (ì ˆëŒ€ì¡°ê±´ í†µê³„ í¬í•¨)"""
        elapsed = datetime.now() - self.start_time
        return {
            "analyzed_count": self.analyzed_count,
            "error_count": self.error_count,
            "filter_passed_count": self.filter_passed_count,
            "filter_failed_count": self.filter_failed_count,
            "total_processed": self.analyzed_count + self.error_count,
            "elapsed_time": elapsed.total_seconds(),
            "success_rate": self.analyzed_count / (self.analyzed_count + self.error_count) * 100 if (self.analyzed_count + self.error_count) > 0 else 0,
            "filter_pass_rate": self.filter_passed_count / (self.filter_passed_count + self.filter_failed_count) * 100 if (self.filter_passed_count + self.filter_failed_count) > 0 else 0
        }

def validate_absolute_conditions_in_file(file_path, logger):
    """
    ì €ì¥ëœ íŒŒì¼ì˜ ì¢…ëª©ë“¤ì´ ì‹¤ì œë¡œ ì ˆëŒ€ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì¦
    
    Args:
        file_path: ê²€ì¦í•  JSON íŒŒì¼ ê²½ë¡œ
        logger: ë¡œê±° ê°ì²´
    """
    try:
        if not os.path.exists(file_path):
            logger.warning(f"ê²€ì¦í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not data:
            logger.warning("ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"ğŸ“‹ {file_path} íŒŒì¼ì˜ {len(data)}ê°œ ì¢…ëª© ì ˆëŒ€ì¡°ê±´ ê²€ì¦ ì‹œì‘")
        
        valid_count = 0
        invalid_count = 0
        
        for item in data:
            code = item.get('code', 'Unknown')
            name = item.get('name', 'Unknown')
            signals = item.get('signals', [])
            
            # ì ˆëŒ€ì¡°ê±´ í™•ì¸
            has_ma5_below_ma20 = "5ì¼ì„ 20ì¼ì„ ì•„ë˜" in signals
            filter_status = item.get('filter_status', '')
            
            if has_ma5_below_ma20 and filter_status == 'ì ˆëŒ€ì¡°ê±´í†µê³¼':
                valid_count += 1
                logger.debug(f"âœ… {name}({code}): ì ˆëŒ€ì¡°ê±´ í™•ì¸")
            else:
                invalid_count += 1
                logger.warning(f"âš ï¸ {name}({code}): ì ˆëŒ€ì¡°ê±´ ì˜ì‹¬")
                if not has_ma5_below_ma20:
                    logger.warning(f"   - 5ì¼ì„ 20ì¼ì„ ì•„ë˜ ì‹ í˜¸ ì—†ìŒ")
                if filter_status != 'ì ˆëŒ€ì¡°ê±´í†µê³¼':
                    logger.warning(f"   - í•„í„° ìƒíƒœ: {filter_status}")
        
        logger.info(f"ğŸ“Š ê²€ì¦ ì™„ë£Œ: ìœ íš¨ {valid_count}ê°œ, ì˜ì‹¬ {invalid_count}ê°œ")
        
        if invalid_count > 0:
            logger.warning(f"âš ï¸ {invalid_count}ê°œ ì¢…ëª©ì´ ì ˆëŒ€ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            logger.info("âœ… ëª¨ë“  ì¢…ëª©ì´ ì ˆëŒ€ì¡°ê±´ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ì„ ìƒˆë¡œìš´ ì´ë¦„ìœ¼ë¡œ í˜¸ì¶œí•˜ëŠ” ë˜í¼ (í•˜ìœ„ í˜¸í™˜ì„±)
def save_backtest_candidates(candidates, logger):
    """ê¸°ì¡´ í•¨ìˆ˜ëª… ì§€ì›"""
    return save_enhanced_backtest_candidates(candidates, logger, include_filter_info=True)

def format_multi_signal_message(grade, stocks):
    """ê¸°ì¡´ í•¨ìˆ˜ëª… ì§€ì›"""
    return format_enhanced_multi_signal_message(grade, stocks)

def format_signal_combination_message(combinations):
    """ê¸°ì¡´ í•¨ìˆ˜ëª… ì§€ì›"""
    return format_enhanced_signal_combination_message(combinations)

# ìƒˆë¡œìš´ Progress Tracker í´ë˜ìŠ¤ (ê¸°ì¡´ í˜¸í™˜ì„±)
ProgressTracker = EnhancedProgressTracker
