"""
ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
JSON ì²˜ë¦¬, ë¡œê¹…, ë©”ì‹œì§€ í¬ë§·íŒ… ë“±
"""
import json
import logging
import os
import requests
import time
import numpy as np
import pandas as pd
from datetime import datetime
from logging.handlers import TimedRotatingFileHandler

def setup_logger(log_dir="logs", log_filename="buying_stocks.log", when="midnight", backup_count=7):
    """ë¡œê¹… ì„¤ì •"""
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_filename)

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    if logger.hasHandlers():
        logger.handlers.clear()

    handler = TimedRotatingFileHandler(
        log_path, when=when, interval=1, backupCount=backup_count, encoding='utf-8'
    )
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger


def convert_numpy_types(obj):
    """numpy íƒ€ìž…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ìž…ìœ¼ë¡œ ë³€í™˜"""
    if hasattr(obj, 'item'):  # numpy scalarì´ë©´ Python ê¸°ë³¸ íƒ€ìž…ìœ¼ë¡œ ë³€í™˜
        return obj.item()
    elif isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, pd.Series):
        return obj.tolist()
    elif isinstance(obj, pd.DataFrame):
        return obj.to_dict('records')
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, datetime):
        return obj.isoformat()
    else:
        return obj


def safe_json_save(data, filename):
    """ì•ˆì „í•œ JSON ì €ìž¥ í•¨ìˆ˜"""
    try:
        # 1ë‹¨ê³„: numpy íƒ€ìž… ë³€í™˜
        converted_data = convert_numpy_types(data)
        
        # 2ë‹¨ê³„: JSON ì§ë ¬í™” í…ŒìŠ¤íŠ¸
        json.dumps(converted_data, ensure_ascii=False)
        
        # 3ë‹¨ê³„: íŒŒì¼ ì €ìž¥
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(converted_data, f, ensure_ascii=False, indent=2)
        
        return True, None
        
    except Exception as e:
        return False, str(e)


def send_discord_message(message, webhook_url):
    """ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ì „ì†¡"""
    if not webhook_url:
        print("âŒ Discord webhook URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
        
    print(message)
    MAX_LENGTH = 2000
    chunks = [message[i:i+MAX_LENGTH] for i in range(0, len(message), MAX_LENGTH)]
    
    for chunk in chunks:
        data = {"content": chunk}
        try:
            response = requests.post(webhook_url, json=data, timeout=10)
            response.raise_for_status()
        except Exception as e:
            print(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")
        time.sleep(0.5)


def format_multi_signal_message(grade, stocks):
    """ë‹¤ì¤‘ì‹ í˜¸ ì¢…ëª© ë©”ì‹œì§€ í¬ë§·íŒ…"""
    if not stocks:
        return ""
    
    grade_info = {
        "ultra_strong": {"icon": "ðŸš€", "name": "ì´ˆê°•ë ¥ ë§¤ìˆ˜ì‹ í˜¸", "desc": "5ì  ì´ìƒ"},
        "strong": {"icon": "ðŸ”¥", "name": "ê°•ë ¥ ë§¤ìˆ˜ì‹ í˜¸", "desc": "4ì "},
        "moderate": {"icon": "â­", "name": "ë³´í†µ ë§¤ìˆ˜ì‹ í˜¸", "desc": "3ì "},
        "weak": {"icon": "âš¡", "name": "ì•½í•œ ë§¤ìˆ˜ì‹ í˜¸", "desc": "2ì "},
        "single": {"icon": "ðŸ’¡", "name": "ë‹¨ì¼ ë§¤ìˆ˜ì‹ í˜¸", "desc": "1ì "}
    }
    
    info = grade_info[grade]
    header = f"{info['icon']} **[{info['name']} ({info['desc']})]**\n"
    
    stock_lines = []
    for stock in sorted(stocks, key=lambda x: x['score'], reverse=True):
        signals_text = ", ".join(stock['signals'])
        
        line = f"- {stock['name']} ({stock['code']}) - {stock['score']}ì \n"
        line += f"  ðŸ“Š [{signals_text}]"
        if 'foreign' in stock and stock['foreign']:
            line += f"\n  ðŸ’° ì™¸êµ­ì¸: {stock['foreign']}"
        stock_lines.append(line)
    
    return header + "\n".join(stock_lines)


def format_signal_combination_message(combinations):
    """ì‹ í˜¸ ì¡°í•© íŒ¨í„´ ë©”ì‹œì§€ í¬ë§·íŒ…"""
    if not combinations:
        return ""
    
    header = "ðŸ” **[ì¸ê¸° ì‹ í˜¸ ì¡°í•© íŒ¨í„´]**\n"
    combo_lines = []
    
    # ì¡°í•©ë³„ ì¢…ëª© ìˆ˜ë¡œ ì •ë ¬
    sorted_combos = sorted(combinations.items(), key=lambda x: len(x[1]), reverse=True)
    
    for combo, stocks in sorted_combos[:10]:  # ìƒìœ„ 10ê°œ ì¡°í•©ë§Œ
        if len(stocks) >= 2:  # 2ê°œ ì´ìƒ ì¢…ëª©ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì¡°í•©ë§Œ
            combo_lines.append(f"â€¢ **{combo}** ({len(stocks)}ê°œ ì¢…ëª©)")
            combo_lines.append(f"  â†’ {', '.join(stocks[:5])}")  # ìµœëŒ€ 5ê°œ ì¢…ëª©ë§Œ í‘œì‹œ
            if len(stocks) > 5:
                combo_lines.append(f"  â†’ ì™¸ {len(stocks)-5}ê°œ ì¢…ëª©")
    
    return header + "\n".join(combo_lines) if combo_lines else ""


def save_backtest_candidates(candidates, logger):
    """ë°±í…ŒìŠ¤íŠ¸ í›„ë³´ ì¢…ëª©ì„ JSON íŒŒì¼ë¡œ ì €ìž¥"""
    try:
        # score ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ 10ê°œë§Œ ì„ íƒ
        sorted_candidates = sorted(candidates, key=lambda x: x['score'], reverse=True)[:10]
        
        logger.debug(f"ì €ìž¥í•  ë°ì´í„° ê°œìˆ˜: {len(sorted_candidates)}")
        
        # ì•ˆì „í•œ JSON ì €ìž¥
        success, error = safe_json_save(sorted_candidates, "trading_list.json")
        
        if success:
            logger.info(f"âœ… trading_list.json ì €ìž¥ ì™„ë£Œ: {len(sorted_candidates)}ê°œ ì¢…ëª©")
        else:
            logger.error(f"âŒ trading_list.json ì €ìž¥ ì‹¤íŒ¨: {error}")
            
            # ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ: pickleë¡œ ì €ìž¥
            try:
                import pickle
                with open("trading_list.pkl", "wb") as f:
                    pickle.dump(sorted_candidates, f)
                logger.info("âœ… ëŒ€ì•ˆìœ¼ë¡œ trading_list.pklì— ì €ìž¥ ì™„ë£Œ")
            except Exception as pickle_error:
                logger.error(f"âŒ pickle ì €ìž¥ë„ ì‹¤íŒ¨: {pickle_error}")
                
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ ì €ìž¥ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")


def load_stock_codes_from_file(file_path):
    """íŒŒì¼ì—ì„œ ì¢…ëª© ì½”ë“œì™€ ì¢…ëª©ëª…ì„ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return [], {}
    
    file_extension = os.path.splitext(file_path)[1].lower()
    stock_codes = []
    stock_names = {}
    
    try:
        if file_extension == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                if data and isinstance(data[0], dict):
                    # [{"code": "034020", "name": "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", ...}, ...] í˜•íƒœ
                    if 'code' in data[0]:
                        for item in data:
                            if 'code' in item:
                                code = str(item['code']).zfill(6)
                                name = item.get('name', code)
                                stock_codes.append(code)
                                stock_names[code] = name
                        print(f"âœ… JSON ê°ì²´ ë°°ì—´ì—ì„œ {len(stock_codes)}ê°œ ì¢…ëª© ë¡œë“œ")
                    else:
                        print(f"âŒ ê°ì²´ì— 'code' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return [], {}
                else:
                    # ["062040", "278470", ...] í˜•íƒœ
                    stock_codes = [str(code).zfill(6) for code in data]
                    stock_names = {code: code for code in stock_codes}
                    print(f"âœ… JSON ë°°ì—´ì—ì„œ {len(stock_codes)}ê°œ ì¢…ëª© ë¡œë“œ")
                    
        # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ì„± ê²€ì‚¬
        unique_codes = []
        unique_names = {}
        for code in stock_codes:
            if code and len(code) == 6 and code.isdigit():
                if code not in unique_codes:
                    unique_codes.append(code)
                    unique_names[code] = stock_names.get(code, code)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì¢…ëª©ì½”ë“œ ì œì™¸: {code}")
        
        print(f"ðŸ“Š ìµœì¢… {len(unique_codes)}ê°œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ")
        return unique_codes, unique_names
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_path}): {e}")
        return [], {}


class ProgressTracker:
    """ì§„í–‰ìƒí™© ì¶”ì  í´ëž˜ìŠ¤"""
    
    def __init__(self, total_count):
        self.total_count = total_count
        self.analyzed_count = 0
        self.error_count = 0
        self.start_time = datetime.now()
    
    def update(self, success=True):
        """ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸"""
        if success:
            self.analyzed_count += 1
        else:
            self.error_count += 1
        
        # 50ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
        total_processed = self.analyzed_count + self.error_count
        if total_processed % 50 == 0:
            elapsed = datetime.now() - self.start_time
            rate = total_processed / elapsed.total_seconds() * 60  # ë¶„ë‹¹ ì²˜ë¦¬ìœ¨
            print(f"ì§„í–‰ ìƒí™©: {total_processed}/{self.total_count} "
                  f"(ì„±ê³µ: {self.analyzed_count}, ì˜¤ë¥˜: {self.error_count}) "
                  f"ì²˜ë¦¬ìœ¨: {rate:.1f}ê°œ/ë¶„")
    
    def get_summary(self):
        """ìµœì¢… ìš”ì•½ ë°˜í™˜"""
        elapsed = datetime.now() - self.start_time
        return {
            "analyzed_count": self.analyzed_count,
            "error_count": self.error_count,
            "total_processed": self.analyzed_count + self.error_count,
            "elapsed_time": elapsed.total_seconds(),
            "success_rate": self.analyzed_count / (self.analyzed_count + self.error_count) * 100 if (self.analyzed_count + self.error_count) > 0 else 0
        }
